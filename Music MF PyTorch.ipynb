{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.sparse as sps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "URM_file = open('data/train.csv', 'r')\n",
    "\n",
    "def rowSplit (rowString):\n",
    "    split = rowString.split(',')\n",
    "    split[0] = int(split[0])\n",
    "    split[1] = int(split[1])\n",
    "    result = tuple(split)\n",
    "    return result\n",
    "\n",
    "next(URM_file)\n",
    "\n",
    "URM_tuples = []\n",
    "for line in URM_file:\n",
    "    URM_tuples.append(rowSplit(line))\n",
    "    \n",
    "URM_tuples[0:10]\n",
    "\n",
    "playlist_list, track_list = zip(*URM_tuples)\n",
    "\n",
    "playlist_list = list(playlist_list)\n",
    "track_list = list(track_list)\n",
    "ratings_list = np.ones(len(playlist_list))\n",
    "\n",
    "URM_all = sps.coo_matrix((ratings_list, (playlist_list, track_list)))\n",
    "URM_all = URM_all.tocsr()\n",
    "\n",
    "from Notebooks_utils.data_splitter import train_test_holdout\n",
    "\n",
    "URM_train, URM_test = train_test_holdout(URM_all, train_perc = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_factors = 10\n",
    "\n",
    "n_playlists, n_tracks = URM_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "playlist_factors = torch.nn.Embedding(num_embeddings = n_playlists, embedding_dim = num_factors)\n",
    "track_factors = torch.nn.Embedding(num_embeddings = n_tracks, embedding_dim = num_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50446, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(20635, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=1, bias=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1 = torch.nn.Linear(in_features = num_factors, out_features = 1)\n",
    "\n",
    "layer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_function = torch.nn.ReLU()\n",
    "\n",
    "activation_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "playlist_index = [15]\n",
    "track_index = [42]\n",
    "\n",
    "track_index = torch.Tensor(track_index).type(torch.LongTensor)\n",
    "playlist_index = torch.Tensor(playlist_index).type(torch.LongTensor)\n",
    "\n",
    "playlist_index = Variable(playlist_index)\n",
    "track_index = Variable(track_index)\n",
    "\n",
    "current_playlist_factors = playlist_factors(playlist_index)\n",
    "current_track_factors = track_factors(track_index)\n",
    "\n",
    "element_wise_product = torch.mul(current_playlist_factors, current_track_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2705,  0.2640, -1.6621,  0.8074,  1.0417, -1.4686,  0.0150,  2.0636,\n",
       "         -0.8746, -1.9344]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_playlist_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5640,  0.5401, -0.3379,  0.1828,  1.9412, -1.9180, -0.9178,  1.3724,\n",
       "          0.2269, -0.6731]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_track_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1526,  0.1426,  0.5615,  0.1476,  2.0222,  2.8168, -0.0138,  2.8322,\n",
       "         -0.1984,  1.3021]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_wise_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is [[0.]]\n"
     ]
    }
   ],
   "source": [
    "prediction = layer_1(element_wise_product)\n",
    "prediction = activation_function(prediction)\n",
    "\n",
    "prediction_numpy = prediction.detach().numpy()\n",
    "\n",
    "print(\"Prediction is {}\".format(prediction_numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 Create a Model python object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF_MSE_PyTorch_model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_playlists, n_tracks, n_factors):\n",
    "\n",
    "        super(MF_MSE_PyTorch_model, self).__init__()\n",
    "\n",
    "        self.n_playlists = n_playlists\n",
    "        self.n_tracks = n_tracks\n",
    "        self.n_factors = n_factors\n",
    "\n",
    "        self.playlist_factors = torch.nn.Embedding(num_embeddings = self.n_playlists, embedding_dim = self.n_factors)\n",
    "        self.track_factors = torch.nn.Embedding(num_embeddings = self.n_tracks, embedding_dim = self.n_factors)\n",
    "\n",
    "        self.layer_1 = torch.nn.Linear(in_features = self.n_factors, out_features = 1)\n",
    "\n",
    "        self.activation_function = torch.nn.ReLU()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, playlist_coordinates, track_coordinates):\n",
    "\n",
    "        current_playlist_factors = self.playlist_factors(playlist_coordinates)\n",
    "        current_track_factors = self.track_factors(track_coordinates)\n",
    "\n",
    "        prediction = torch.mul(current_playlist_factors, current_track_factors)\n",
    "\n",
    "        prediction = self.layer_1(prediction)\n",
    "        prediction = self.activation_function(prediction)\n",
    "\n",
    "        return prediction\n",
    "\n",
    "\n",
    "\n",
    "    def get_W(self):\n",
    "\n",
    "        return self.playlist_factors.weight.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "    def get_H(self):\n",
    "\n",
    "        return self.track_factors.weight.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF_MSE_PyTorch: Using CPU\n"
     ]
    }
   ],
   "source": [
    "use_cuda = False\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"MF_MSE_PyTorch: Using CUDA\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"MF_MSE_PyTorch: Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyTorchModel = MF_MSE_PyTorch_model(n_playlists, n_tracks, num_factors).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreadalcin/Developer/University/RecSys_Course_2018/venv/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "lossFunction = torch.nn.MSELoss(size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "optimizer = torch.optim.Adagrad(pyTorchModel.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class DatasetIterator_URM(Dataset):\n",
    "\n",
    "    def __init__(self, URM):\n",
    "\n",
    "        URM = URM.tocoo()\n",
    "\n",
    "        self.n_data_points = URM.nnz\n",
    "\n",
    "        self.playlist_track_coordinates = np.empty((self.n_data_points, 2))\n",
    "\n",
    "        self.playlist_track_coordinates[:,0] = URM.row.copy()\n",
    "        self.playlist_track_coordinates[:,1] = URM.col.copy()\n",
    "        self.rating = URM.data.copy().astype(np.float)\n",
    "\n",
    "        self.playlist_track_coordinates = torch.Tensor(self.playlist_track_coordinates).type(torch.LongTensor)\n",
    "        self.rating = torch.Tensor(self.rating)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Format is (row, col, data)\n",
    "        :param index:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        return self.playlist_track_coordinates[index, :], self.rating[index]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return self.n_data_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "dataset_iterator = DatasetIterator_URM(URM_train)\n",
    "\n",
    "train_data_loader = DataLoader(dataset = dataset_iterator,\n",
    "                   batch_size = batch_size,\n",
    "                   shuffle = True,\n",
    "                   #num_workers = 2,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 of 4847, loss 128.0904\n",
      "Batch 100 of 4847, loss 133.2470\n",
      "Batch 200 of 4847, loss 133.2471\n",
      "Batch 300 of 4847, loss 126.5507\n",
      "Batch 400 of 4847, loss 132.5936\n",
      "Batch 500 of 4847, loss 131.2636\n",
      "Batch 600 of 4847, loss 127.4965\n",
      "Batch 700 of 4847, loss 126.3322\n",
      "Batch 800 of 4847, loss 125.1275\n",
      "Batch 900 of 4847, loss 131.3287\n",
      "Batch 1000 of 4847, loss 128.0992\n",
      "Batch 1100 of 4847, loss 133.8381\n",
      "Batch 1200 of 4847, loss 132.2967\n",
      "Batch 1300 of 4847, loss 130.2351\n",
      "Batch 1400 of 4847, loss 125.2143\n",
      "Batch 1500 of 4847, loss 130.6168\n",
      "Batch 1600 of 4847, loss 136.3115\n",
      "Batch 1700 of 4847, loss 126.7903\n",
      "Batch 1800 of 4847, loss 131.0420\n",
      "Batch 1900 of 4847, loss 133.6401\n",
      "Batch 2000 of 4847, loss 131.8910\n",
      "Batch 2100 of 4847, loss 127.1952\n",
      "Batch 2200 of 4847, loss 126.9921\n",
      "Batch 2300 of 4847, loss 136.7751\n",
      "Batch 2400 of 4847, loss 129.1919\n",
      "Batch 2500 of 4847, loss 130.7349\n",
      "Batch 2600 of 4847, loss 127.8732\n",
      "Batch 2700 of 4847, loss 127.1365\n",
      "Batch 2800 of 4847, loss 122.8699\n",
      "Batch 2900 of 4847, loss 131.3351\n",
      "Batch 3000 of 4847, loss 126.2662\n",
      "Batch 3100 of 4847, loss 127.6782\n",
      "Batch 3200 of 4847, loss 131.4662\n",
      "Batch 3300 of 4847, loss 125.9044\n",
      "Batch 3400 of 4847, loss 126.0269\n",
      "Batch 3500 of 4847, loss 127.0810\n",
      "Batch 3600 of 4847, loss 125.3832\n",
      "Batch 3700 of 4847, loss 133.7364\n",
      "Batch 3800 of 4847, loss 127.5055\n",
      "Batch 3900 of 4847, loss 132.1041\n",
      "Batch 4000 of 4847, loss 131.3349\n",
      "Batch 4100 of 4847, loss 126.6056\n",
      "Batch 4200 of 4847, loss 128.1383\n",
      "Batch 4300 of 4847, loss 130.9519\n",
      "Batch 4400 of 4847, loss 134.6182\n",
      "Batch 4500 of 4847, loss 119.6599\n",
      "Batch 4600 of 4847, loss 128.5734\n",
      "Batch 4700 of 4847, loss 134.5731\n",
      "Batch 4800 of 4847, loss 125.1755\n"
     ]
    }
   ],
   "source": [
    "for num_batch, (input_data, label) in enumerate(train_data_loader, 0):\n",
    "    \n",
    "    cumulative_loss = 0\n",
    "\n",
    "    # On windows requires int64, on ubuntu int32\n",
    "    #input_data_tensor = Variable(torch.from_numpy(np.asarray(input_data, dtype=np.int64))).to(self.device)\n",
    "    input_data_tensor = Variable(input_data).to(device)\n",
    "\n",
    "    label_tensor = Variable(label).to(device)\n",
    "\n",
    "\n",
    "    playlist_coordinates = input_data_tensor[:,0]\n",
    "    track_coordinates = input_data_tensor[:,1]\n",
    "\n",
    "    # FORWARD pass\n",
    "    prediction = pyTorchModel(playlist_coordinates, track_coordinates)\n",
    "\n",
    "    # Pass prediction and label removing last empty dimension of prediction\n",
    "    loss = lossFunction(prediction.view(-1), label_tensor)\n",
    "    \n",
    "\n",
    "    if num_batch % 100 == 0:\n",
    "        \n",
    "        print(\"Batch {} of {}, loss {:.4f}\".format(num_batch, len(train_data_loader), loss.data.item()))\n",
    "        \n",
    "        #if num_batch == 2000:\n",
    "        #    print(\"Interrupting train\")\n",
    "        #    break\n",
    "    \n",
    "\n",
    "    # BACKWARD pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = pyTorchModel.get_W()\n",
    "H = pyTorchModel.get_H()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50446, 10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20635, 10)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender(object):\n",
    "    \n",
    "    def __init__(self, URM, W, H):\n",
    "        self.URM = URM\n",
    "        self.W = W\n",
    "        self.H = H.T\n",
    "        \n",
    "    def recommend(self, playlist_id, at=None, exclude_seen=True, output=False):\n",
    "        # compute the scores using the dot product\n",
    "        playlist_factors = self.W[playlist_id]\n",
    "        scores = playlist_factors.dot(self.H).ravel()\n",
    "\n",
    "        if exclude_seen:\n",
    "            scores = self.filter_seen(playlist_id, scores)\n",
    "\n",
    "        # rank items\n",
    "        ranking = scores.argsort()[::-1]\n",
    "        \n",
    "        # output for challenge\n",
    "        if output:\n",
    "            print(\"{}, {}\".format(playlist_id, \" \".join(ranking)))\n",
    "        \n",
    "        return ranking[:at]\n",
    "    \n",
    "    \n",
    "    def filter_seen(self, playlist_id, scores):\n",
    "\n",
    "        start_pos = self.URM.indptr[playlist_id]\n",
    "        end_pos = self.URM.indptr[playlist_id+1]\n",
    "\n",
    "        playlist = self.URM.indices[start_pos:end_pos]\n",
    "        \n",
    "        scores[playlist] = -np.inf\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated user 0 of 50446\n",
      "Evaluated user 10000 of 50446\n",
      "Evaluated user 20000 of 50446\n",
      "Evaluated user 30000 of 50446\n",
      "Evaluated user 40000 of 50446\n",
      "Evaluated user 50000 of 50446\n",
      "Recommender performance is: Precision = 0.0002, Recall = 0.0004, MAP = 0.0001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.0002275456671512542,\n",
       " 'recall': 0.00040667485390355376,\n",
       " 'MAP': 0.00011600968423789306}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender = Recommender(URM_train, W, H)\n",
    "\n",
    "from Notebooks_utils.evaluation_function import evaluate_algorithm\n",
    "\n",
    "evaluate_algorithm(URM_test, recommender, at=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
