{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.sparse as sps\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "URM_file = open('data/train.csv', 'r')\n",
    "\n",
    "def rowSplit (rowString):\n",
    "    split = rowString.split(',')\n",
    "    split[0] = int(split[0])\n",
    "    split[1] = int(split[1])\n",
    "    result = tuple(split)\n",
    "    return result\n",
    "\n",
    "next(URM_file)\n",
    "\n",
    "URM_tuples = []\n",
    "for line in URM_file:\n",
    "    URM_tuples.append(rowSplit(line))\n",
    "    \n",
    "URM_tuples[0:10]\n",
    "\n",
    "playlist_list, track_list = zip(*URM_tuples)\n",
    "\n",
    "playlist_list = list(playlist_list)\n",
    "track_list = list(track_list)\n",
    "\n",
    "playlist_unique = list(set(playlist_list))\n",
    "track_unique = list(set(track_list))\n",
    "\n",
    "ratings_list = np.ones(len(playlist_list))\n",
    "\n",
    "URM_all = sps.coo_matrix((ratings_list, (playlist_list, track_list)))\n",
    "URM_all = URM_all.tocsr()\n",
    "\n",
    "from Notebooks_utils.data_splitter import train_test_holdout\n",
    "\n",
    "URM_train, URM_test = train_test_holdout(URM_all, train_perc = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<50446x20635 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 969203 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<50446x20635 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 242588 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 1: Sampling</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible playlists: 50445 out of 50446\n"
     ]
    }
   ],
   "source": [
    "n_playlists = URM_train.shape[0]\n",
    "n_tracks = URM_train.shape[1]\n",
    "\n",
    "eligiblePlaylists = []\n",
    "\n",
    "for playlist_id in range(n_playlists):\n",
    "    \n",
    "    start_pos = URM_train.indptr[playlist_id]\n",
    "    end_pos = URM_train.indptr[playlist_id+1]\n",
    "    \n",
    "    if len(URM_train.data[start_pos:end_pos]) > 0:\n",
    "        eligiblePlaylists.append(playlist_id)\n",
    "        \n",
    "print(\"Eligible playlists: {} out of {}\".format(len(eligiblePlaylists), n_playlists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sampleTriplet():\n",
    "    playlist_id = np.random.choice(n_playlists)\n",
    "    \n",
    "    playlist_seen_items = URM_train[playlist_id].indices\n",
    "    pos_item_id = np.random.choice(playlist_seen_items)\n",
    "    \n",
    "    neg_item_selected = False\n",
    "    \n",
    "    while (not neg_item_selected):\n",
    "        neg_item_id = np.random.randint(0, n_tracks)\n",
    "        \n",
    "        if (neg_item_id not in playlist_seen_items):\n",
    "            neg_item_selected = True\n",
    "            \n",
    "    return playlist_id, pos_item_id, neg_item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sps\n",
    "\n",
    "\n",
    "def similarityMatrixTopK(item_weights, forceSparseOutput = True, k=100, verbose = False, inplace=True):\n",
    "    \"\"\"\n",
    "    The function selects the TopK most similar elements, column-wise\n",
    "\n",
    "    :param item_weights:\n",
    "    :param forceSparseOutput:\n",
    "    :param k:\n",
    "    :param verbose:\n",
    "    :param inplace: Default True, WARNING matrix will be modified\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    assert (item_weights.shape[0] == item_weights.shape[1]), \"selectTopK: ItemWeights is not a square matrix\"\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Generating topK matrix\")\n",
    "\n",
    "    nitems = item_weights.shape[1]\n",
    "    k = min(k, nitems)\n",
    "\n",
    "    # for each column, keep only the top-k scored items\n",
    "    sparse_weights = not isinstance(item_weights, np.ndarray)\n",
    "\n",
    "    if not sparse_weights:\n",
    "\n",
    "        idx_sorted = np.argsort(item_weights, axis=0)  # sort data inside each column\n",
    "\n",
    "        if inplace:\n",
    "            W = item_weights\n",
    "        else:\n",
    "            W = item_weights.copy()\n",
    "\n",
    "        # index of the items that don't belong to the top-k similar items of each column\n",
    "        not_top_k = idx_sorted[:-k, :]\n",
    "        # use numpy fancy indexing to zero-out the values in sim without using a for loop\n",
    "        W[not_top_k, np.arange(nitems)] = 0.0\n",
    "\n",
    "        if forceSparseOutput:\n",
    "            W_sparse = sps.csr_matrix(W, shape=(nitems, nitems))\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Sparse TopK matrix generated in {:.2f} seconds\".format(time.time() - start_time))\n",
    "\n",
    "            return W_sparse\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Dense TopK matrix generated in {:.2f} seconds\".format(time.time()-start_time))\n",
    "\n",
    "        return W\n",
    "\n",
    "    else:\n",
    "        # iterate over each column and keep only the top-k similar items\n",
    "        data, rows_indices, cols_indptr = [], [], []\n",
    "\n",
    "        item_weights = check_matrix(item_weights, format='csc', dtype=np.float32)\n",
    "\n",
    "        for item_idx in range(nitems):\n",
    "\n",
    "            cols_indptr.append(len(data))\n",
    "\n",
    "            start_position = item_weights.indptr[item_idx]\n",
    "            end_position = item_weights.indptr[item_idx+1]\n",
    "\n",
    "            column_data = item_weights.data[start_position:end_position]\n",
    "            column_row_index = item_weights.indices[start_position:end_position]\n",
    "\n",
    "            non_zero_data = column_data!=0\n",
    "\n",
    "            idx_sorted = np.argsort(column_data[non_zero_data])  # sort by column\n",
    "            top_k_idx = idx_sorted[-k:]\n",
    "\n",
    "            data.extend(column_data[non_zero_data][top_k_idx])\n",
    "            rows_indices.extend(column_row_index[non_zero_data][top_k_idx])\n",
    "\n",
    "\n",
    "        cols_indptr.append(len(data))\n",
    "\n",
    "        # During testing CSR is faster\n",
    "        W_sparse = sps.csc_matrix((data, rows_indices, cols_indptr), shape=(nitems, nitems), dtype=np.float32)\n",
    "        W_sparse = W_sparse.tocsr()\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Sparse TopK matrix generated in {:.2f} seconds\".format(time.time() - start_time))\n",
    "\n",
    "        return W_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class SLIM_BPR_Recommender(object):\n",
    "    \"\"\" SLIM_BPR recommender with cosine similarity and no shrinkage\"\"\"\n",
    "\n",
    "    def __init__(self, URM):\n",
    "        self.URM = URM\n",
    "        \n",
    "        self.URM_mask = self.URM.copy()\n",
    "        self.URM_mask.eliminate_zeros()\n",
    "        \n",
    "        self.n_playlists = self.URM_mask.shape[0]\n",
    "        self.n_tracks = self.URM_mask.shape[1]\n",
    "        \n",
    "        self.similarity_matrix = np.zeros((self.n_tracks,self.n_tracks))\n",
    "        \n",
    "        self.uneligiblePlaylists = []\n",
    "\n",
    "        for playlist_id in range(self.n_playlists):\n",
    "\n",
    "            start_pos = self.URM_mask.indptr[playlist_id]\n",
    "            end_pos = self.URM_mask.indptr[playlist_id+1]\n",
    "\n",
    "            if len(self.URM_mask.indices[start_pos:end_pos]) <= 0:\n",
    "                self.uneligiblePlaylists.append(playlist_id)\n",
    "        \n",
    "        # print(self.uneligiblePlaylists)\n",
    "        # print(\"Fraction of uneligiblePlaylists playlists: {:.2f}\".format(float(len(self.uneligiblePlaylists))/self.n_playlists))\n",
    "\n",
    "\n",
    "    def sampleTriplet(self):\n",
    "\n",
    "        # By randomly selecting a user in this way we could end up \n",
    "        # with a user with no interactions\n",
    "        #user_id = np.random.randint(0, n_users)\n",
    "\n",
    "        playlist_id = np.random.randint(0, n_playlists)\n",
    "        \n",
    "        while playlist_id in self.uneligiblePlaylists:\n",
    "            playlist_id = np.random.randint(0, n_playlists)\n",
    "    \n",
    "        playlist_seen_items = URM_train[playlist_id].indices    \n",
    "        pos_item_id = np.random.choice(playlist_seen_items)\n",
    "    \n",
    "        neg_item_selected = False\n",
    "    \n",
    "        while (not neg_item_selected):\n",
    "            neg_item_id = np.random.randint(0, n_tracks)\n",
    "        \n",
    "            if (neg_item_id not in playlist_seen_items):\n",
    "                neg_item_selected = True\n",
    "            \n",
    "        return playlist_id, pos_item_id, neg_item_id\n",
    "        \n",
    "    def epochIteration(self):\n",
    "\n",
    "        # Get number of available interactions\n",
    "        numPositiveIteractions = int(self.URM_mask.nnz*0.01)\n",
    "\n",
    "        start_time_epoch = time.time()\n",
    "        start_time_batch = time.time()\n",
    "\n",
    "        # Uniform user sampling without replacement\n",
    "        for num_sample in range(numPositiveIteractions):\n",
    "\n",
    "            # Sample\n",
    "            playlist_id, positive_item_id, negative_item_id = self.sampleTriplet()\n",
    "\n",
    "            userSeenItems = self.URM_mask[playlist_id,:].indices\n",
    "\n",
    "            # Prediction\n",
    "            x_i = self.similarity_matrix[positive_item_id, userSeenItems].sum()\n",
    "            x_j = self.similarity_matrix[negative_item_id, userSeenItems].sum()\n",
    "\n",
    "            # Gradient\n",
    "            x_ij = x_i - x_j\n",
    "\n",
    "            gradient = 1 / (1 + np.exp(x_ij))\n",
    "\n",
    "            # Update\n",
    "            self.similarity_matrix[positive_item_id, userSeenItems] += self.learning_rate * gradient\n",
    "            self.similarity_matrix[positive_item_id, positive_item_id] = 0\n",
    "\n",
    "            self.similarity_matrix[negative_item_id, userSeenItems] -= self.learning_rate * gradient\n",
    "            self.similarity_matrix[negative_item_id, negative_item_id] = 0\n",
    "\n",
    "\n",
    "            if(time.time() - start_time_batch >= 30 or num_sample == numPositiveIteractions-1):\n",
    "                print(\"Processed {} ( {:.2f}% ) in {:.2f} seconds. Sample per second: {:.0f}\".format(\n",
    "                    num_sample,\n",
    "                    100.0* float(num_sample)/numPositiveIteractions,\n",
    "                    time.time() - start_time_batch,\n",
    "                    float(num_sample) / (time.time() - start_time_epoch)))\n",
    "\n",
    "                start_time_batch = time.time()\n",
    "\n",
    "    \n",
    "    def params(self, learning_rate=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def optimize(self, epochs = 1):\n",
    "        for numEpoch in range(epochs):\n",
    "            self.epochIteration()\n",
    "            \n",
    "    def build(self, topK=100):\n",
    "        self.output_matrix = self.similarity_matrix.T\n",
    "        self.output_matrix = similarityMatrixTopK(self.output_matrix, k=topK)    \n",
    "    \n",
    "    def fit(self, learning_rate=0.01, epochs=10):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "        print(\"fit(): starting epochs\")\n",
    "        for numEpoch in range(self.epochs):\n",
    "            self.epochIteration()\n",
    "            \n",
    "        self.similarity_matrix = self.similarity_matrix.T\n",
    "        \n",
    "        print(\"fit(): topK\")\n",
    "        self.similarity_matrix = similarityMatrixTopK(self.similarity_matrix, k=100)\n",
    "        \n",
    "        print(\"fit(): end\")\n",
    "        \n",
    "        \n",
    "    def recommend(self, playlist_id, at=None, exclude_seen=True, output=False):\n",
    "        # compute the scores using the dot product\n",
    "        playlist = self.URM[playlist_id]\n",
    "        scores = playlist.dot(self.output_matrix).toarray().ravel()\n",
    "\n",
    "        if exclude_seen:\n",
    "            scores = self.filter_seen(playlist_id, scores)\n",
    "\n",
    "        # rank items\n",
    "        ranking = scores.argsort()[::-1]\n",
    "        \n",
    "        # output for challenge\n",
    "        if output:\n",
    "            print(\"{}, {}\".format(playlist_id, \" \".join(ranking)))\n",
    "        \n",
    "        return ranking[:at]\n",
    "    \n",
    "    \n",
    "    def filter_seen(self, playlist_id, scores):\n",
    "\n",
    "        start_pos = self.URM.indptr[playlist_id]\n",
    "        end_pos = self.URM.indptr[playlist_id+1]\n",
    "\n",
    "        playlist = self.URM.indices[start_pos:end_pos]\n",
    "        \n",
    "        scores[playlist] = -np.inf\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 9691 ( 99.99% ) in 2.29 seconds. Sample per second: 4227\n",
      "Processed 9691 ( 99.99% ) in 1.98 seconds. Sample per second: 4885\n",
      "Processed 9691 ( 99.99% ) in 2.00 seconds. Sample per second: 4834\n",
      "Processed 9691 ( 99.99% ) in 1.96 seconds. Sample per second: 4950\n",
      "Processed 9691 ( 99.99% ) in 2.08 seconds. Sample per second: 4668\n",
      "Processed 9691 ( 99.99% ) in 1.92 seconds. Sample per second: 5050\n",
      "Processed 9691 ( 99.99% ) in 2.14 seconds. Sample per second: 4527\n",
      "Processed 9691 ( 99.99% ) in 2.02 seconds. Sample per second: 4803\n",
      "Processed 9691 ( 99.99% ) in 1.89 seconds. Sample per second: 5133\n",
      "Processed 9691 ( 99.99% ) in 1.98 seconds. Sample per second: 4898\n",
      "Processed 9691 ( 99.99% ) in 1.84 seconds. Sample per second: 5268\n",
      "Processed 9691 ( 99.99% ) in 1.88 seconds. Sample per second: 5152\n",
      "Processed 9691 ( 99.99% ) in 1.90 seconds. Sample per second: 5097\n",
      "Processed 9691 ( 99.99% ) in 1.86 seconds. Sample per second: 5222\n",
      "Processed 9691 ( 99.99% ) in 1.88 seconds. Sample per second: 5157\n",
      "Processed 9691 ( 99.99% ) in 1.81 seconds. Sample per second: 5356\n",
      "Processed 9691 ( 99.99% ) in 1.77 seconds. Sample per second: 5479\n",
      "Processed 9691 ( 99.99% ) in 1.80 seconds. Sample per second: 5395\n",
      "Processed 9691 ( 99.99% ) in 1.90 seconds. Sample per second: 5114\n",
      "Processed 9691 ( 99.99% ) in 1.82 seconds. Sample per second: 5324\n",
      "Processed 9691 ( 99.99% ) in 1.69 seconds. Sample per second: 5718\n",
      "Processed 9691 ( 99.99% ) in 1.68 seconds. Sample per second: 5771\n",
      "Processed 9691 ( 99.99% ) in 1.71 seconds. Sample per second: 5661\n",
      "Processed 9691 ( 99.99% ) in 1.68 seconds. Sample per second: 5769\n",
      "Processed 9691 ( 99.99% ) in 1.69 seconds. Sample per second: 5728\n",
      "Processed 9691 ( 99.99% ) in 1.67 seconds. Sample per second: 5788\n",
      "Processed 9691 ( 99.99% ) in 1.68 seconds. Sample per second: 5782\n",
      "Processed 9691 ( 99.99% ) in 1.67 seconds. Sample per second: 5791\n",
      "Processed 9691 ( 99.99% ) in 1.76 seconds. Sample per second: 5502\n",
      "Processed 9691 ( 99.99% ) in 1.77 seconds. Sample per second: 5487\n"
     ]
    }
   ],
   "source": [
    "recommender = SLIM_BPR_Recommender(URM_train)\n",
    "recommender.params(learning_rate=0.1)\n",
    "recommender.optimize(epochs=30)\n",
    "recommender.build(topK=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated user 0 of 50446\n",
      "Evaluated user 10000 of 50446\n"
     ]
    }
   ],
   "source": [
    "from Notebooks_utils.evaluation_function import evaluate_algorithm\n",
    "\n",
    "evaluate_algorithm(URM_test, recommender, at=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
